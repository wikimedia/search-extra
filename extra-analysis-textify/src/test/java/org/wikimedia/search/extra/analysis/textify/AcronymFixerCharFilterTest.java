package org.wikimedia.search.extra.analysis.textify;

import java.io.IOException;
import java.io.StringReader;

import org.apache.lucene.analysis.BaseTokenStreamTestCase;
import org.apache.lucene.analysis.TokenStream;
import org.junit.Test;

public class AcronymFixerCharFilterTest extends BaseTokenStreamTestCase {

    private TokenStream ezTokStream(String s) throws IOException {
        return whitespaceMockTokenizer(new AcronymFixerCharFilter(new StringReader(s)));
    }

    @Test
    public void testSimpleLatinAcronymFixer() throws IOException {
        assertTokenStreamContents(
            ezTokStream("cat a.c.r.o.n.y.m .F.i.X.e.R. T.E.S.T. dog"),
            new String[]{"cat", "acronym", ".FiXeR.", "TEST.", "dog"},
            new int[]{0,  4, 18, 30, 39},  // start offsets
            new int[]{3, 17, 29, 38, 42}); // end offsets
    }

    @Test
    public void testNonAcronymPeriods() throws IOException {
        assertTokenStreamContents(
            ezTokStream("example.org e.xa.m.ple.o.rg"),
            new String[]{"example.org", "e.xa.m.ple.o.rg"},
            new int[]{0,  12},  // start offsets
            new int[]{11, 27}); // end offsets
    }

    @Test
    public void testNonLatinAcronymFixer() throws IOException {
        // Latin, Greek, Cyrillic, Bengali, Devenagari, Khmer, Arabic, Latin
        assertTokenStreamContents(
            ezTokStream("Q.Î£.Ğ”.à¦….à¤Œ.á.Ø¨.Z. Î±.Îº.Ï.Ï‰.Î½.Ï.Î¼.Î¹.Î¿ .Ğ°.Ğº.Ñ€.Ğ¾.Ğ½.Ğ¸.Ğ¼."),
            new String[]{"QÎ£Ğ”à¦…à¤ŒáØ¨Z.", "Î±ÎºÏÏ‰Î½ÏÎ¼Î¹Î¿", ".Ğ°ĞºÑ€Ğ¾Ğ½Ğ¸Ğ¼."},
            new int[]{0,  17, 35},  // start offsets
            new int[]{16, 34, 50}); // end offsets

        // Hiragana, Thai, Hanzi
        assertTokenStreamContents(
            ezTokStream("ã†.ãµ.ãµ. à¸¡.à¸›.à¸—. æ·„ï¼é’ï¼é½Šï¼ç™»ï¼"),
            new String[]{"ã†ãµãµ.", "à¸¡à¸›à¸—.", "æ·„é’é½Šç™»ï¼"},
            new int[]{0,  7, 14},  // start offsets
            new int[]{6, 13, 22}); // end offsets
    }

    @Test
    public void testAbugidaAcronymFixer() throws IOException {
        // Devanagari, Bengali, Kannada, Myanmar
        assertTokenStreamContents(
            ezTokStream("à¤•à¥‡.à¤.à¤Ÿà¤¿.à¤. à¦¸à¦¾.à¦¸à¦¾.à¦ªà§‚. à²….à²¸à²‚.à²²à²¿.à²µ. á€•.á€¡.á€™.á€–."),
            new String[]{"à¤•à¥‡à¤à¤Ÿà¤¿à¤.", "à¦¸à¦¾à¦¸à¦¾à¦ªà§‚.", "à²…à²¸à²‚à²²à²¿à²µ.", "á€•á€¡á€™á€–."},
            new int[]{0,  11, 21, 32},  // start offsets
            new int[]{10, 20, 31, 40}); // end offsets
    }

    @Test
    public void testExtendedCharacterAcronymFixer() throws IOException {
        assertTokenStreamContents(
            ezTokStream("A.Æ˜.Æ”.áº .Ä.Ã€.á¼.á¾ˆ.Ô„.Ôˆ.Ô˜.A."),
            new String[]{"AÆ˜Æ”áº ÄÃ€á¼á¾ˆÔ„ÔˆÔ˜A."},
            new int[]{0},   // start offsets
            new int[]{24}); // end offsets
    }

    @Test
    public void testCombiningChars() throws IOException {
        assertTokenStreamContents(
            ezTokStream(".X.XÌ„.XÌ†.XÌ£Ì¥Ì.XÌ®.X. A.âƒB.âƒ C.à¤¾D"),
            new String[]{".XXÌ„XÌ†XÌ£Ì¥ÌXÌ®X.", "AâƒBâƒ Cà¤¾D"},
            new int[]{0,  20},  // start offsets
            new int[]{19, 30}); // end offsets
    }

    @Test
    public void testInvisibles() throws IOException {
        assertTokenStreamContents(
            ezTokStream("E\ufe01.F\u00ad.G\u202d.H\u202a.I\u200e.J\u202c." +
            "K\u2069.L\u034f.M\u200c.N\u200d.O\u2060.P\u200b.Q."),
                // variation selector, soft hyphen, left-to-right override, left-
                // to-right embedding, left-to-right mark, pop directional formatting,
                // pop directional isolate, combining grapheme joiner, zero-width
                // non-joiner, zero-width joiner, word joiner, zero-width space
            new String[]{"E\ufe01F\u00adG\u202dH\u202aI\u200eJ\u202c" +
                         "K\u2069L\u034fM\u200cN\u200dO\u2060P\u200bQ."},
            new int[]{0},   // start offsets
            new int[]{38}); // end offsets
    }

    @Test
    public void testThirtyTwoBitAcronymFixer() throws IOException {
        assertTokenStreamContents(
            ezTokStream("A.ğ€.ğ’œ.ğ”¸.ğ•¬.ğ– .ğ˜¼.ğ™°.ğšª.ğœ.ğ’.ğƒ.ğ….ğ†.A."),
            new String[]{"Ağ€ğ’œğ”¸ğ•¬ğ– ğ˜¼ğ™°ğšªğœğ’ğƒğ…ğ†A."},
            new int[]{0},   // start offsets
            new int[]{43}); // end offsets
    }

    @Test
    public void testEdgeCasesAcronymFixer() throws IOException {
        // string begins or ends with periods
        assertTokenStreamContents(
            ezTokStream(".a.c.r.o.n.y.m."),
            new String[]{".acronym."},
            new int[]{0},   // start offsets
            new int[]{15}); // end offsets

        // string begins or ends WITHOUT periods
        assertTokenStreamContents(
            ezTokStream("a.c.r.o.n.y.m"),
            new String[]{"acronym"},
            new int[]{0},   // start offsets
            new int[]{13}); // end offsets
    }

    @Test
    public void testTitleCaseAcronymFixer() throws IOException {
        assertTokenStreamContents(
            ezTokStream("A.Ç‡.Çˆ.Ç‰.A."),
            new String[]{"AÇ‡ÇˆÇ‰A."},
            new int[]{0},   // start offsets
            new int[]{10}); // end offsets
    }

    @Test
    public void testFullwidthPeriodsAcronymFixer() throws IOException {
        assertTokenStreamContents(
            ezTokStream("ï¼¡ï¼ï½ƒï¼ï½’ï¼ï½ï¼ï½ï¼ï½™ï¼ï½ï¼ Aï¼cï¼rï¼oï¼nï¼yï¼m " +
            "ï¼Xï¼XÌ„ï¼XÌ†ï¼XÌ£Ì¥Ìï¼XÌ®ï¼Xï¼ Aï¼âƒBï¼âƒ Cï¼à¤¾D Qï¼Î£ï¼Ğ”ï¼à¦…ï¼à¤Œï¼áï¼ Aï¼Ç‡ï¼Çˆï¼Ç‰ï¼A"),
            new String[]{"ï¼¡ï½ƒï½’ï½ï½ï½™ï½ï¼", "Acronym", "ï¼XXÌ„XÌ†XÌ£Ì¥ÌXÌ®Xï¼", "AâƒBâƒ Cà¤¾D", "QÎ£Ğ”à¦…à¤Œáï¼", "AÇ‡ÇˆÇ‰A"},
            new int[]{0,  15, 29, 49, 60, 73},  // start offsets
            new int[]{14, 28, 48, 59, 72, 82}); // end offsets
    }

    @Test
    public void testRidiculousAcronymFixer() throws IOException {
        // test very many combining marks and/or invisibles
        assertTokenStreamContents(
            ezTokStream("A.Ô‰âƒÌ†Ì¤\u00ad.Çˆâƒ Ì¥Ì‚.x. x.aÌ¸Ì…Ì€Í“Ì¬Í™.bÌµÌ¿ÍÍ‘Ì¾Ì€Í‚Í’ÌÍ›Ì’ÌŠÌ“Í•.cÌ´ÍŠÌÌˆÌ“ÌšÌ‹Ì›ÌˆÍ†Í…Í”."),
            new String[]{"AÔ‰âƒÌ†Ì¤\u00adÇˆâƒ Ì¥Ì‚x.", "xaÌ¸Ì…Ì€Í“Ì¬Í™bÌµÌ¿ÍÍ‘Ì¾Ì€Í‚Í’ÌÍ›Ì’ÌŠÌ“Í•cÌ´ÍŠÌÌˆÌ“ÌšÌ‹Ì›ÌˆÍ†Í…Í”."},
            new int[]{0,  16},  // start offsets
            new int[]{15, 56}); // end offsets
    }

    @Test
    public void testCircleBuffCapacity() throws IOException {
        // test the buff capacity right at 25. 24 should be fine. 25 will fill the
        // buffer but not overflow, and 26 should be too many.
        // 24 == 22 soft hyphens between "a." and "b.", plus "b." -- buff not full
        assertTokenStreamContents(
            ezTokStream("24 a.Â­Â­Â­Â­Â­Â­Â­Â­Â­Â­Â­Â­Â­Â­Â­Â­Â­Â­Â­Â­Â­Â­b."),
            new String[]{"24", "aÂ­Â­Â­Â­Â­Â­Â­Â­Â­Â­Â­Â­Â­Â­Â­Â­Â­Â­Â­Â­Â­Â­b."},
            new int[]{0, 3},   // start offsets
            new int[]{2, 29}); // end offsets

        // 25 == 23 soft hyphens between "a." and "b.", plus "b." -- buff full, but
        // works
        assertTokenStreamContents(
            ezTokStream("25 a.Â­Â­Â­Â­Â­Â­Â­Â­Â­Â­Â­Â­Â­Â­Â­Â­Â­Â­Â­Â­Â­Â­Â­b."),
            new String[]{"25", "aÂ­Â­Â­Â­Â­Â­Â­Â­Â­Â­Â­Â­Â­Â­Â­Â­Â­Â­Â­Â­Â­Â­Â­b."},
            new int[]{0, 3},   // start offsets
            new int[]{2, 30}); // end offsets

        // 26 == 24 soft hyphens between "a." and "b.", plus "b." -- buff too small,
        // fails gracefully
        assertTokenStreamContents(
            ezTokStream("26 a.Â­Â­Â­Â­Â­Â­Â­Â­Â­Â­Â­Â­Â­Â­Â­Â­Â­Â­Â­Â­Â­Â­Â­Â­Â­Â­b."),
            new String[]{"26", "a.Â­Â­Â­Â­Â­Â­Â­Â­Â­Â­Â­Â­Â­Â­Â­Â­Â­Â­Â­Â­Â­Â­Â­Â­Â­Â­b."},
            new int[]{0, 3},   // start offsets
            new int[]{2, 33}); // end offsets

        // test way too many combining marks and/or invisibles (>>25). 50 soft
        // hyphens between "a." and "b." is way, way too many and acronym fixing
        // should fail, but gracefully
        assertTokenStreamContents(
            ezTokStream("50 a.Â­Â­Â­Â­Â­Â­Â­Â­Â­Â­Â­Â­Â­Â­Â­Â­Â­Â­Â­Â­Â­Â­Â­Â­Â­Â­Â­Â­Â­Â­Â­Â­Â­Â­Â­Â­Â­Â­Â­Â­Â­Â­Â­Â­Â­Â­Â­Â­Â­Â­b."),
            new String[]{"50", "a.Â­Â­Â­Â­Â­Â­Â­Â­Â­Â­Â­Â­Â­Â­Â­Â­Â­Â­Â­Â­Â­Â­Â­Â­Â­Â­Â­Â­Â­Â­Â­Â­Â­Â­Â­Â­Â­Â­Â­Â­Â­Â­Â­Â­Â­Â­Â­Â­Â­Â­b."},
            new int[]{0, 3},   // start offsets
            new int[]{2, 57}); // end offsets
    }

    @Test
    public void testMiscNonAcronymicText() throws IOException { // these should all be unchanged
        // Latin, Cyrillic, Hanzi, Hangul
        assertTokenStreamContents(
            ezTokStream("Wikipedia Ğ’Ğ¸ĞºĞ¸Ğ¿ĞµĞ´Ğ¸Ñ ç»´åŸºç™¾ç§‘ ìœ„í‚¤ë°±ê³¼"),
            new String[]{"Wikipedia", "Ğ’Ğ¸ĞºĞ¸Ğ¿ĞµĞ´Ğ¸Ñ", "ç»´åŸºç™¾ç§‘", "ìœ„í‚¤ë°±ê³¼"});

        // Armenian, Hebrew, Greek, Arabic, Georgian
        assertTokenStreamContents(
            ezTokStream("ÕÕ«Ö„Õ«ÕºÕ¥Õ¤Õ«Õ¡ ×•×™×§×™×¤×“×™×” Î’Î¹ÎºÎ¹Ï€Î±Î¯Î´ÎµÎ¹Î± ÙˆÙŠÙƒÙŠØ¨ÙŠØ¯ÙŠ áƒ•áƒ˜áƒ™áƒ˜áƒáƒ”áƒ“áƒ˜áƒ"),
            new String[]{"ÕÕ«Ö„Õ«ÕºÕ¥Õ¤Õ«Õ¡", "×•×™×§×™×¤×“×™×”", "Î’Î¹ÎºÎ¹Ï€Î±Î¯Î´ÎµÎ¹Î±", "ÙˆÙŠÙƒÙŠØ¨ÙŠØ¯ÙŠ", "áƒ•áƒ˜áƒ™áƒ˜áƒáƒ”áƒ“áƒ˜áƒ"});

        // Devanagari, Thai, Tamil, Bengali, IPA
        assertTokenStreamContents(
            ezTokStream("à¤µà¤¿à¤•à¤¿à¤ªà¥€à¤¡à¤¿à¤¯à¤¾ à¸§à¸´à¸à¸´à¸à¸µà¹€à¸”à¸µà¸¢ à®µà®¿à®•à¯à®•à®¿à®ªà¯à®ªà¯€à®Ÿà®¿à®¯à®¾ à¦‰à¦‡à¦•à¦¿à¦ªà¦¿à¦¡à¦¿à¦¯à¦¼à¦¾ ËŒwÉªkÉªËˆpiËdiÉ™"),
            new String[]{"à¤µà¤¿à¤•à¤¿à¤ªà¥€à¤¡à¤¿à¤¯à¤¾", "à¸§à¸´à¸à¸´à¸à¸µà¹€à¸”à¸µà¸¢", "à®µà®¿à®•à¯à®•à®¿à®ªà¯à®ªà¯€à®Ÿà®¿à®¯à®¾", "à¦‰à¦‡à¦•à¦¿à¦ªà¦¿à¦¡à¦¿à¦¯à¦¼à¦¾", "ËŒwÉªkÉªËˆpiËdiÉ™"});
    }

}
